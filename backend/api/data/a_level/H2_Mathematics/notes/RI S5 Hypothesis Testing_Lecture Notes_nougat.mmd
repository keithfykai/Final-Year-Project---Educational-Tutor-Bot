## Chapter S5: Hypothesis Testing

**SYLLABUS INCLUDES**

* concepts of null hypothesis (H\({}_{0}\) ) and alternative hypotheses (H\({}_{i}\)), test statistic, critical region, critical value, level of significance and \(p\)-value
* a sample from a normal population of known variance
- a large sample from any population
* 1-tail and 2-tail tests
* Interpretation of the results of a hypothesis test in the context of the problem

**PRE-REQUISTES**

* S3 Normal Distribution
* S4 Sampling

**CONTENT**

	* 1.1 Null and Alternative Hypotheses
	* 1.2 Level of Significance
	* 1.3 Test Statistic, Critical Value, Critical Region, \(p\)-value
	* 1.4 Performing a Hypothesis Test
* **Hypothesis Tests on Population Mean*
	* 2.1 Using the \(z\)-test

## Appendix 0.1 Type I and Type II Errors

[MISSING_PAGE_FAIL:2]

**Example 1**: For each of the following cases, formulate appropriate null and alternative hypotheses.

**(a)**: Flour is sold, on average, at 500 g per bag. Test whether the average mass of the contents of a bag is being understated.

To test \(\mathrm{H}_{0}\) : \(\mu=500\) vs \(\mathrm{H}_{1}\) : \(\mu>500\)
**(b)**: The company Kookakola produces cans of aerated water. The company claims that the mean content of aerated water is 505 ml. Test whether it is overstating the mean content.

To test \(\mathrm{H}_{0}\) : \(\mu=505\) vs \(\mathrm{H}_{1}\) : \(\mu<505\)
**(c)**: A machine produces components of mean length 10 cm if it is correctly set up. A random sample of components produced by the machine is taken, and the length of each component is measured. Test whether the machine is correctly set up.

To test \(\mathrm{H}_{0}\) : \(\mu=10\) vs \(\mathrm{H}_{1}\) : \(\mu\neq 10\)

When carrying out a hypothesis test, we are looking for significant evidence to reject \(\mathrm{H}_{0}\) in favour of \(\mathrm{H}_{1}\). But what constitutes significant evidence?

### Level of Significance

When testing hypotheses there is always a possibility of making a wrong decision or error.

The threshold under which we consider \(\mathrm{H}_{0}\) to be sufficiently unlikely to be correct is called the **level of significance** (or **significance level**) of the hypothesis test.

The **level of significance** (or significance level) of a hypothesis test, denoted by \(\alpha\), is defined as the **probability of rejecting \(\mathrm{H}_{0}\) when \(\mathrm{H}_{0}\) is true**.

i.e. Level of significance = P(reject \(\mathrm{H}_{0}\) when \(\mathrm{H}_{0}\) is in fact true) = P(reject \(\mathrm{H}_{0}\)\(\mathrm{H}_{0}\) is true)

In the context of our introductory scenario,

\(\alpha=\) P(concluding that the **mean** lifespan of a light bulb is shorter than 600 hrs

when it actually is 600 hrs).

As such, it is tempting to choose \(\alpha\) to be as small as possible, since the conclusion is a wrong one; so why not pick \(\alpha=0\)? Refer to Appendix 1 (Type I and Type II Errors) for more information.

Appropriate values for \(\alpha\) depends on which area of study we are engaged in and are usually chosen by consensus. For the social sciences, it might be chosen as high as \(\alpha=0.3\), the biological and medical fields mostly use \(\alpha=0.05\) (5% level of significance) or \(\alpha=0.01\) (1% level of significance), while the physical sciences might use a value as small as \(\alpha=10^{-6}\).

Note that **the lower the level of significance (i.e. the smaller \(\alpha\) is), the stronger the evidence needed to reject \(\mathrm{H}_{0}\)**.

### Test Statistic, Critical Value, Critical Region, \(p\)-value

#### Test Statistic

To carry out the test, the focus moves from \(X\), the lifespan of lightbulbs to the distribution of \(\vec{X}\), the mean lifespan from a sample of lightbulbs. \(\vec{X}\) is the **test statistic** for the population mean \(\mu\).

A **test statistic** is a random variable used to make the decision "do not reject \(\mathrm{H}_{0}\)" or "reject \(\mathrm{H}_{0}\)". The test statistic measures the degree of agreement between a sample of data and the null hypothesis. Its observed value changes randomly from one random sample to another.

We will discuss in Section 2, how to make use of the test statistic, \(\vec{X}\), and its distribution, when performing a hypothesis test on the population mean, \(\mu\).

In our example, \(\mathrm{H}_{0}\): \(\mu\) = 600 \(\mathrm{vs}\) \(\mathrm{H}_{1}\): \(\mu\) < 600.

Under the assumption that the null hypothesis is true, the population mean and standard deviation are \(\mu\) = 600 and \(\sigma\) = 60 (these values are given by the manufacturer), so, by the Central Limit Theorem, we have \(\vec{X}\) \(\sim\) N\(\left(\) 600, \(\frac{60^{2}}{50}\right)\) approximately, since \(n\) = 50 is large.

#### Critical Value, Critical Region

The result of the test depends on the whereabouts of the test value in the sampling distribution, 586 hours (observed mean value of lifespan of a random sample of 50 bulbs). If the value is close to 600 hours then it is likely to have come from a distribution with mean 600 hours. On the other hand, if it is far away from 600 hours, then it is unlikely to have come from a distribution with mean 600 hours.

A decision needs to be taken about the cut-off point, \(c\), known as the **critical value** which indicates the boundary of the region where values would be considered too far away from 600 hours and therefore unlikely to occur. The region is known as the critical region or rejection region. The value of \(c\) depends on the stated significance level \(\alpha\).

The situation in the original scenario is illustrated below:

\begin{tabular}{|p{113.8pt}|p{113.8pt}|} \hline Distribution of \(\vec{X}\) (under \(H_{0}\) ) & At **5%** level of significance (\(\alpha=0.05\) ), we can find the **critical value**\(c\), \(\mathrm{P}(\vec{X}\leq c)=0.05\) \(c=586.04\) (\(5\) s.f.) \\  & and the **critical region** is \(\left(-\infty\), \(586.04\right]\). \\  & On the other hand with **1%** level of significance (\(\alpha=0.01\) ), we can obtain the **critical region** as \(\left(-\infty\), \(580.26\right]\). \\ \hline \end{tabular} Here, \(\vec{x}=586\in\left(-\infty\), \(586.04\right]\), i.e. \(\vec{x}\) lies in the critical region, so we reject the null hypothesis at the 5% (and 10%) level of significance, in favour of the alternative hypothesis.

On the other hand, at 1% level of significance, \(\vec{x}=586\not\in\left(-\infty\), \(580.26\right]\), i.e. \(\vec{x}\) does not lie in the critical region, so we fail to reject the null hypothesis.

In general, if the level of significance is \(100\,\alpha\) %,

\begin{tabular}{|p{113.8pt}|p{113.8pt}|} \hline For a 1-tail test with \(H_{1};\mu<\mu_{0}\) \(\alpha=P(\vec{X}\leq c)\), \(\alpha=P(\vec{X}\geq c)\), \(\alpha=P(\vec{X}\geq c)\), \(c\) the **critical value**. \\ \hline \end{tabular}

\begin{tabular}{|p{113.8pt}|p{113.8pt}|} \hline For a 2-tail test, we reject \(H_{0}\) if \(\vec{x}\) is too big or too small. In this case, we choose \(c_{1}\) and \(c_{2}\) such that \(\alpha=P(\vec{X}\leq c_{1})+P(\vec{X}\geq c_{2})\).

By symmetry, \(P(\vec{X}\leq c_{1})=P(\vec{X}\geq c_{2})\), so \(\alpha=2P(\vec{X}\leq c_{1})=2P(\vec{X}\geq c_{2})\).

[MISSING_PAGE_POST]

\begin{tabular}{|p{113.8pt}|} \hline \(\alpha\) \\ \hline \end{tabular}

\begin{tabular}{|p{113.8pt}|} \hline \(\alpha\) \\ \hline \(\alpha\) \\ \hline \end{tabular}

\begin{tabular}{|p{113.8pt}|} \hline \(\alpha\) \\ \hline \end{tabular}

[MISSING_PAGE_EMPTY:6]

There are 2 possible outcomes of testing:

**(1)**: If _p_-value \(\leq\alpha\), we **reject**\(\mathrm{H}_{0}\) and conclude that there is **sufficient** evidence against the claim of \(\mathrm{H}_{0}\).
**(2)**: If _p_-value \(>\alpha\), we **do not reject**\(\mathrm{H}_{0}\) and conclude that there is **insufficient** evidence against the claim of \(\mathrm{H}_{0}\).

Since we compare the _p_-value against the significance level to decide whether to reject \(\mathrm{H}_{0}\), the _p_-value is the **smallest level of significance at which \(\mathrm{H}_{0}\) can be rejected**.

**Note:**

"_Do not reject \(\mathrm{H}_{0}\)_" is **not** equivalent to "_accept_\(\mathrm{H}_{0}\)_". In fact, under the framework of hypothesis testing, there is no way to prove that \(\mathrm{H}_{0}\) is true; all we can assess is whether there is sufficient evidence against it.

The _p_-value, together with the value of the associated test statistic, is a convenient summary of the evidence found in experiments and is commonly reported in journals. This leaves it open for the reader to judge the significance of the result. (i.e. choose their own \(\alpha\). ) The _p_-value is often referred to as an **observed** level of significance.

### Performing a Hypothesis Test

Now that we have learnt all the essential elements of a test of hypothesis, below is a framework for carrying out a hypothesis test:

\begin{tabular}{|c|l|} \hline
**Step 1** & Understand the given question and write down the **null hypothesis** \\  & \(\mathrm{H}_{0}\) and the **alternative hypothesis**\(\mathrm{H}_{1}\) \\ \hline
**Step 2** & Write down the **level of significance**\(\alpha\) (usually given in the question) \\ \hline
**Step 3** & Decide on the **test statistic** to be used and determine its **distribution** \\ \hline
**Step 4** & Use the GC to calculate the _p_-**value** \\ \hline
**Step 5** & **Reject \(\mathrm{H}_{0}\)** if _p_-value \(\leq\alpha\), OR \\  & **Do not reject \(\mathrm{H}_{0}\)** if _p_-value \(>\alpha\) \\  & Write down the **conclusion** in the **context of the question** \\ \hline \end{tabular}

Note that aside from Step 3, where we need to decide which test statistic is to be used, the other steps require us to only "write down" certain information or to "use the GC". In essence, once we have decided on the test statistic in Step 3, we would have solved the problem, provided the test statistic is the correct one.

Hypothesis Tests on Population Mean

As mentioned in Section 1.4, we need to decide which test statistic to use. In the A level H2 Math context, we will focus on performing hypothesis tests on population mean, \(\mu\), with the sample mean, \(\overline{X}\), as the test statistic. To work out the distribution of the test statistic, we assume that \(H_{0}\) is true.

**Test Statistic and its distribution**

\begin{tabular}{|c|c|c|} \cline{2-4} \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{**Characteristic of**} & \multicolumn{1}{c|}{**Distribution of test statistic, \(\overline{X}\)**} \\ \hline \multirow{4}{*}{**Population Variance**} & \multirow{2}{*}{(I)} & \multirow{2}{*}{_Normal Population_} & \multirow{2}{*}{\(\overline{X}\sim\text{N}\bigg{(}\mu_{0},\frac{\sigma^{2}}{n}\bigg{)}\)} \\  & & & \\ \cline{1-1} \cline{3-3}  & \multirow{2}{*}{(II)} & \multirow{2}{*}{_Non-normal_} & \multirow{2}{*}{\(\overline{X}\sim\text{N}\bigg{(}\mu_{0},\frac{\sigma^{2}}{n}\bigg{)}\) approximately} \\  & & large sample size & by Central Limit Theorem \\ \hline
**1) Population Variance** & \multirow{2}{*}{(III)} & \multirow{2}{*}{_Normal Population_} & \multirow{2}{*}{\(\overline{X}\sim\text{N}\bigg{(}\mu_{0},\frac{s^{2}}{n}\bigg{)}\) approximately} \\  & & & \\ \cline{1-1} \cline{3-3}  & \multirow{2}{*}{**2) large sample size**} & \multirow{2}{*}{(IV)} & \multirow{2}{*}{_Non-normal_} & \multirow{2}{*}{\(\overline{X}\sim\text{N}\bigg{(}\mu_{0},\frac{s^{2}}{n}\bigg{)}\) approximately} \\  & & & \\ \cline{1-1} \cline{3-3}  & \multirow{2}{*}{_population_} & & \\ \cline{1-1} \cline{3-3}  & & & \\ \cline{1-1} \cline{3-3}  & & & \\ \hline \end{tabular}
**Note:**\(s^{2}\), an unbiased estimate of \(\sigma^{2}\), is used instead.

### Using the \(z\)-test

When the test statistic follows normal distribution, we use the \(z\)**-test**. Thus in all cases above, we use the \(z\)**-test** unless sample size is small and population variance is unknown, which is not included in the H2 Math syllabus. If we know the population variance \(\sigma^{2}\) (Cases I and II as above), we will use it. Otherwise we will estimate it with \(s^{2}\) (Cases III and IV as above).

When the sample size is small and the population variance is known, we can only proceed if we know that the population is normally distributed (Case I as above). For examination questions, this condition will either be given, or you will have to state it as an assumption where applicable.

[MISSING_PAGE_FAIL:9]

[MISSING_PAGE_FAIL:10]

**Example 4**:

A teacher sets an examination paper for students. Let \(X\) be the time, in minutes, taken by a student to complete the examination paper.

She gave the paper to 60 randomly chosen students. The results obtained are summarized as follows:

\[\sum x=3048\quad\text{and}\quad\quad\sum(x-\overline{x})^{2}=465\,.\]
**(i)**: Calculate unbiased estimates of the population mean and population variance.

The teacher wishes to test at the 2% significance level, whether the population mean time taken by a student to complete the examination paper is 50 minutes.
**(ii)**: State appropriate hypotheses for the test, defining any symbols you use.
**(iii)**: Find the critical region for this test and explain what it means in this context.

**Solution**:

\(X\) is the time, in minutes, taken by a student to complete the examination paper.

**(i)**: An unbiased estimate of the population mean is \(\overline{x}=\dfrac{1}{n}\sum x=\dfrac{3048}{60}=50.8\)

An unbiased estimate of the population variance is \(s^{2}=\dfrac{1}{n-1}\sum\left(x-\overline{x}\right)^{2}=\dfrac{465}{59}\)
**(ii)**: Let \(\mu\) minutes be the population mean time taken by a student to complete the examination paper.

To test null hypothesis, \(\mathrm{H}_{0}:\)\(\mu=50\) versus alternative hypothesis, \(\mathrm{H}_{1}:\)\(\mu\neq 50\)
**(iii)**: Perform a 2-tail test at 2% significance level.

Under \(\mathrm{H}_{0}\), since the sample size \(n=60\) is large, by Central Limit Theorem,

\(\overline{X}\sim\mathrm{N}\left(50,\dfrac{465}{59}\atop 60\right)\)approximately.

Use \(s^{2}=\dfrac{465}{59}\). Not allowed to use \(s^{2}=7.88\)

(3sf) as it might lead to loss of accuracy

Using GC, critical region is \(\left(0,49.2\right)\cup\left(50.8,\infty\right)\).

Critical region refers to the range of sample mean time, taken by a student in a sample of 60 randomly chosen students, to complete the examination paper such that there is sufficient evidence at 2% significance level to conclude that the mean time taken by a student to complete the paper is not 50 minutes.

**Example 5**: An electronic device is advertised as being able to retain information stored in it 'for 70 to 90 hours' after power has been switched off. In experiments carried out to test this claim, the retention time in hours, \(X\), was measured on 250 occasions, and the data obtained is summarized by \(\sum(x-76)=683\) and \(\sum(x-76)^{2}=26132\). The population mean and variance of \(X\) are denoted by \(\mu\) and \(\sigma^{2}\) respectively.

**(i)**: Show that, correct to one decimal place, an unbiased estimate of \(\sigma^{2}\) is 97.5.
**(ii)**: Test the hypothesis that \(\mu=80\) against the alternative hypothesis that \(\mu<80\), at 5% significance level.

**Solution**

**(i)**: Let \(Y=X-76\). Then we have \(\sum y=683\), \(\sum y^{2}=26132\).

\(s_{{}_{y}}^{2}=\frac{1}{n-1}\Bigg{[}\sum y^{2}-\frac{\left(\sum y \right)^{2}}{n}\Bigg{]}\)

\(=\frac{1}{249}\Bigg{(}\ 26132-\frac{683^{2}}{250}\Bigg{)}\approx 97.454\)

\(s_{{}_{x}}^{2}=s_{{}_{y}}^{2}=97.5\) (1 d.p.)

\(\therefore\)An unbiased estimate of \(\sigma^{2}\) is 97.5 (1dp)
**(ii)**: To test \(\mathrm{H}_{0}:\ \mu=80\) vs \(\mathrm{H}_{1}:\ \mu<80\)

Perform a 1-tail test at 5% significance level.

Under \(\mathrm{H}_{0}\), since \(n=250\) is large, by Central

Limit Theorem, \(\vec{X}\sim\mathrm{N}\bigg{(}80,\ \frac{97.5}{250}\bigg{)}\) approximately.

From the sample,

\(\vec{y}=\vec{x}-76\)

\(\vec{x}=\vec{y}+76=\frac{683}{250}+76=78.732\)

Using a \(z\)-test,

\(p\)-value \(=\)P(\(\vec{X}\leq 78.732\)) \(=\) 0.0212 (3 s.f.)

Since \(p\)-value \(=0.0212\leq 0.05\), we reject \(\mathrm{H}_{0}\) and conclude that there is sufficient evidence, at 5% significance level, that the mean retention time is less than 80 hours.

**Example 6 [DHS/9758/2019/Prelim/02/Q9a & c]**

The time taken, \(T\) (in minutes), for a 17-year-old student to complete a 5-km run is a random variable with mean 30. After a new training programme is introduced for these students, a random sample of \(n\) students is taken. The mean time and standard deviation for the sample are found to be 28.9 minutes and 4.0 minutes respectively.

**(a)**: Find an unbiased estimate of the population variance in terms of \(n\).
**(b)**: The trainer claims instead that the new training programme is able to improve the mean of \(\tau\), 30 minutes, by at least 5%. The school wants to test his claim.

**(i)**: Write down the null and alternative hypothesis.
**(ii)**: Using the existing sample, the school carried out a test at 1% significance level and found that there was sufficient evidence to reject the trainer's claim. Find the set of values that \(n\) can take, stating any necessary assumption(s) needed to carry out the test.

**Solution**

**(a)**: An unbiased estimate for the population variance, \( s^{2}=\frac{n}{n-1}\Big{(}4^{2}\Big{)}=\frac{16n}{n-1}\) minutes\({}^{2}\)

**(b)(i)**: New population mean timing \(=0.95\times 30=28.5\) minutes

Let \(\mu\) minutes be the population mean time taken by a student to complete the 5-km run.

Null hypothesis, \(\qquad\) H\({}_{0}:\mu=28.5\)

Alternative hypothesis, H\({}_{1}:\mu>28.5\)

**(b)(ii)**: Assumption: \(n\) is large for Central Limit Theorem to apply.

Under H\({}_{0}\), \(\overline{T}\sim\) N\(\left(28.5,\frac{4^{2}}{n-1}\right)\) approximately by Central Limit Theorem

For \(H_{0}\) to be rejected, we need

\(p\)-value\(=\) P\(\left(\overline{T}\geq 28.9\right)\leq 0.01\)

P\(\left(Z\geq\frac{28.9-28.5}{\frac{4}{n-1}}\right)\leq 0.01\)

P\(\left(Z\geq\frac{\sqrt{n-1}}{10}\right)\leq 0.01\)

\(\frac{\sqrt{n-1}}{10}\geq 2.3263\)

\(n\geq 542.2\)

Thus required set \(=\big{\{}n\in\mathbb{Z}:n\geq 543\big{\}}\)

Chapter S5: Hypothesis Testing

Page 13 of 19

## Appendix 1 Type I and Type II Errors

In the practice of statistics, when we perform hypothesis testing, the null hypothesis is presumed to be true, unless there is sufficient evidence against it.

In conducting a hypothesis test, there is of course a probability of arriving at a wrong conclusion about the validity of the alternative hypothesis. This can be very serious, as a wrong conclusion will lead to wrong decisions and courses of action.

There are **two types of error in hypothesis testing**, namely _Type I_ and _Type II Errors_.

\begin{tabular}{|c|c|c|} \hline \begin{tabular}{c} Truth \\ Decision \\ \end{tabular} & \begin{tabular}{c} Null \\ Hypothesis \\ \end{tabular} & \begin{tabular}{c} Alternative \\ Hypothesis \\ \end{tabular} \\ \hline \begin{tabular}{c} Null \\ Hypothesis \\ \end{tabular} & & \begin{tabular}{c} Type II Error \\ (do not reject H\({}_{0}\) \\ when it is false) \\ \end{tabular} \\ \hline \begin{tabular}{c} Alternative \\ Hypothesis \\ \end{tabular} & 
\begin{tabular}{c} Type I Error \\ (reject H\({}_{0}\) when it \\ is true) \\ \end{tabular} & \\ \multicolumn{3}{c|}{Table 1} \\ \end{tabular}

A _Type I Error_ is committed when one wrongly rejects a true null hypothesis and a _Type II Error_ is committed when one fails to reject a false null hypothesis. In practice, a good scientific study will minimize the chance of making such errors.

**Power of a Test**

When performing hypothesis testing, it seems that we should aim to choose \(\alpha\) (the probability of rejecting \(H_{0}\) when it is true) to be as small as possible, since we want to keep the rate of _Type I Error_ fairly low.

So why don't we choose \(\alpha\) to be 0, that is, \(\mathrm{P}(\mathrm{Type\ I\ Error})=0\)?

Note that if we do not reject H\({}_{0}\) regardless of whether it is true or false, then we will never wrongly reject H\({}_{0}\), so \(\alpha=0\). But such a decision rule is meaningless! Moreover, if we do not reject H\({}_{0}\) but H\({}_{0}\) happens to be false, then we are committing Type II Error!

Let \(\beta=\mathrm{P}(\mathrm{Type\ II\ Error})=\mathrm{P}(\mathrm{do\ not\ reject\ H}_{0}\) when H\({}_{0}\) is false).

Then the **power** of a hypothesis test \(=\)1 - \(\beta\), i.e. the probability of correctly rejecting H\({}_{0}\) when H\({}_{0}\) is false.

Thus, \(0\leq\mathrm{power\ }\leq 1\) and other considerations being equal, _the larger the power the better_.

Ideally, we want both \(\alpha\) and \(\beta\) to be as small as possible. However, it turns out that the smaller the \(\alpha\), the larger the \(\beta\) and vice versa. The challenge is to find a balance between the two and to decide which type of error is a more critical mistake! Also, an increase in the sample size will usually reduce both _Type I and Type II Errors_.

#### (I) Criminal Trial Analogy - "innocent until proven guilty"

The criminal trial analogy works like hypothesis testing. Some criminal justice system assumes "**the defendant is innocent until proven guilty**." That is, the defendant is presumed to be innocent. In statistics, the hypotheses will be as follows:

\[\begin{array}{ll}\bullet&\text{H}_{0}\colon\text{Defendant is not guilty (innocent)}\\ \bullet&\text{H}_{1}\colon\text{Defendant is guilty}\]

The prosecution team then tries to collect evidence (e.g. hair samples, finger prints etc), hoping to find "sufficient evidence" to "reject the null hypothesis", that is to refute the initial assumption of innocence.

If the evidence presented by the prosecution does not prove that the defendant is guilty beyond a reasonable doubt (do not have sufficient evidence at \(\omega\)% level of significance that the alternative hypothesis is true), then based on the given evidence, the jury cannot reject that the _possibility_ that the defendant _is_ innocent (do not reject the null hypothesis). In other words, it has not been proven that the defendant is _innocent_ but it cannot be proven legally that the defendant is _guilty_.

On the other hand, if the evidence presented by the prosecution is sufficient beyond a reasonable doubt to convict the defendant (have sufficient evidence at \(a\)% level of significance that the alternative hypothesis is true), then the jury refute the initial assumption that the defendant is innocent (reject the null hypothesis) and deems the defendant guilty.

Criminal trials like statistical tests are susceptible to error. Let's review the two types of errors that can be made in criminal trials:

\begin{tabular}{|c|c|c|} \hline \begin{tabular}{c} Jury \\ Decision \\ \end{tabular} & \begin{tabular}{c} Not Guilty \\ \end{tabular} & \begin{tabular}{c} Guilty \\ \end{tabular} \\ \hline \begin{tabular}{c} Not Guilty \\ \end{tabular} & \begin{tabular}{c} Error \\ \end{tabular} & \begin{tabular}{c} Error \\ (guilty going \\ scot - free) \\ \end{tabular} \\ \hline \begin{tabular}{c} Guilty \\ \end{tabular} & 
\begin{tabular}{c} Error \\ (innocent being \\ convicted) \\ \end

### (II) False Positives and False Negatives in Health Screening

In medical statistics, **false positives** and **false negatives** are concepts that also correspond to _Type I and Type II errors_ in statistical hypothesis testing (Table 1).

\begin{tabular}{|c|c|c|} \hline Test Truth Result & Does not have disease & Has disease \\ \hline Negative & & False Negative \\ \hline Positive & False Positive & \\ \hline \end{tabular}

Table 3

A false negative is a test result that indicates a person does not have a disease or condition when the person actually does have it. Correspondingly, a false positive is a test result that indicates a person has a specific disease or condition when the person actually does not have it.

### **The False Positive Paradox**

**If a test for a disease is 99% accurate and you receive a positive result, what are the odds that you actually have the disease?**

Many people _would think_ that since the test is 99% accurate, a person who received positive results has about a 99% chance of having the disease. This might be wrong! If the disease is very common, your odds of actually having the disease might approach 99%. However, the rarer the disease is, the less accurate the test and the lower the odds that you actually have the disease. The reason involves _conditional probability_.

Suppose the disease affects one out of every 1000 people in the population. Assume that the test accuracy is constant for patients with or without the disease. Using a tree diagram,

\(\Rightarrow\)\(P\big{(}\)test positive & has disease\(\big{)}\) = 0.99\(\times\) 0.001 = 0.00099

\[P\big{(}\text{ has disease}\big{|}\text{ test positive}\big{)} = \frac{P\big{(}\text{test positive \& has disease}\big{)}}{P\big{(}\text{test positive}\big{)}}\] \[= \frac{0.00099}{0.99\times 0.001+0.01\times 0.999}\] \[= 0.09016\]

Thus, for any person who tests positive, the odds of them having the disease is about 9%.

**Can we then believe a negative test result?**

\(P\big{(}\)test negative \(\big{|}\text{ no disease}\big{)}\) = 0.99

\(\Rightarrow\)\(P\big{(}\)test negative & no disease\(\big{)}\) = 0.99\(\times\) 0.999 = 0.98901

\(P\big{(}\) no disease\(\big{|}\) test negative\(\big{)}\) = \(\frac{P\big{(}\)test negative & no disease\(\big{)}}{P\big{(}\)test negative\(\big{)}}\)

\(=\frac{0.98901}{0.01\times 0.001+0.99\times 0.999}\)

\(=0.99989\)

Thus, a negative result is _almost certainly correct_.

It is important and necessary to look at the conditional probabilities in the interpretation of test results. This could be a real problem in the field of medicine, as patients or even doctors might not fully understand how to interpret such information from health screening statistics.

**False Negatives**

False negatives create two problems. The first is a false sense of security. For example, if your manufacturing line is unable to detect defective items, it might be thought that the process is running more effectively than it actually is. The second, potentially more serious issue, is that potentially dangerous situations may be missed. For example, a crippling computer virus can wreak havoc if not detected, or an individual with cancer may not receive timely treatment.

## Appendix 2 Performing the z-test using GC

With reference to Example 2, here are the GC screenshots when performing a _z_-test.

\begin{tabular}{|l|l|} \hline
**1** & Press [stat] and scroll right to select **TESTS** & EDIT CALC **TESTS** \\  & Select **1: Z - Test** & 2: T-Test \\  & Select **1: Z - Test** & 3: Z-Same2Test \\  & Select **4: Z-SameTest** \\  & Select **5: I-ProzTest** \\  & Select **6: Z-ProzTest** \\  & Select **7: Z-Interval** \\  & Select **8: IInterval** \\
**2** & Select **Stats** \\  & Key in the values of \(\mu_{0},\ \sigma,\ \overline{x},\ n\) and select the required \\  & 1-tail or 2-tail test \\  & & \\ \hline \end{tabular}

\begin{tabular}{|l|l|} \hline Take note that \\ unlike "normalcdf", \\ we key in \(\sigma\) here \\ and not \(\dfrac{\sigma}{\sqrt{n}}\). \\ \hline \end{tabular}

\begin{tabular}{|l|l|} \hline
**3** & Select **Calculate** and press [enter] to obtain the _p_-value. \\ OR & \\ \hline \end{tabular}

You may also select **Draw** and press [enter] for the area \\  & associated with the _p_-value. \\ \hline \end{tabular}

Chapter S5: Hypothesis Testing

Page 18 of 19

## Summary