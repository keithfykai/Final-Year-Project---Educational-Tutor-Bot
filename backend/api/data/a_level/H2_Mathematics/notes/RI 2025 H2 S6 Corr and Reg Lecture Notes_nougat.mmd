## Chapter S6: Correlation and Regression

**Syllabus will include**

* Use of scatter diagram to judge if there is a plausible linear relationship between the two variables
* Correlation coefficient as a measure of the fit of a linear model to the scatter diagram
* Interpreting the product moment correlation coefficient (in particular, values close to \(-1\), \(0\) and \(1\))
* Concepts of linear regression and method of least squares to find the equation of the regression line
* Concepts of interpolation and extrapolation
* Use of the appropriate regression line to make prediction or estimate a value in practical situations, including explaining how well the situation is modelled by the linear regression model
* Use of a square, reciprocal or logarithmic transformation to achieve linearity

**CONTENT**

**1**: **Terminology**

1.1 Describing Variables

1.2 Scatter Diagram

1.2.1 Producing a Scatter Diagram using the Graphing calculator

1.2.2 Interpreting Scatter Diagrams

**2**: **Product Moment Correlation Coefficient**

2.1 Calculating the Value of the Product Moment Correlation Coefficient

2.2 Properties of the Product Moment Correlation Coefficient

2.3 Interpreting Correlation

2.3.1 Importance of Scatter Diagram

2.3.2 Correlation does not imply Causation

**3**: **Linear Regression**

3.1 Least Squares Regression Line of \(y\) on \(x\)

3.2 Least Squares Regression Line of \(x\) on \(y\)

3.3 Calculating the Least Squares Regression Lines and Product Moment

Correlation Coefficient using the Graphing calculator

**4**: **Application and Interpretation**

**5**: **Linearisation of Data**

Appendix: Equivalence of the 2 Formulae for the Product Moment Correlation Coefficient

## Introduction

Suppose that you are helping a proud mother to keep track of the weight of her newborn. After monitoring the infant's weight (_y_ kg) for a period of time (_t_ days), you obtain the following data:

\begin{tabular}{|c|c c c c c c c|} \hline \(t\) & 7 & 32 & 71 & 97 & 188 & 273 & 409 \\ \hline \(y\) & 4.43 & 4.88 & 6.31 & 7.18 & 10.63 & 13.60 & 17.95 \\ \hline \end{tabular} Can you then tell the mother how much her baby will weigh by the next month? What about the next year? How certain would you be of your prediction? Can you further use your data to check if the infant's growth is normal?

In this chapter, we will deal with the skills required to answer the above questions. Statistical inference entails the study of **correlation** between variables and **regression analysis**, the art and science of finding these relationships between variables. Empirical data rarely corroborate exactly with theoretical mathematical models, hence the need for statistical analysis to accommodate such deviations.

## 1 Terminology

### Describing Variables

* The data in the above example are a set of pairs of values for two variables. This is an example of **bivariate data**, where each observation requires the values of two variables.
* Since an infant's weight is dependent upon his/her age, \(t\) is the **independent variable** and \(y\) is the **dependent variable** in the above example.
* Sometimes the independent variable is **controlled** so that the variable only assumes a set of predetermined values.

### Example 1

Identify the dependent and independent variables in each of the scenarios below.

**(a)** An object is heated up and its volume measured at different temperatures. The following table shows eight of these measurements.

\begin{tabular}{|c|c c c c c c c c c|} \hline Temperature (\({}^{\circ}\)C), \(t\) & 30 & 40 & 50 & 60 & 70 & 80 & 90 & 100 \\ Volume (m\({}^{3}\)), \(v\) & 1.000 & 1.256 & 1.395 & 1.523 & 1.648 & 1.699 & 1.712 & 1.735 \\ \hline \end{tabular}

Ans:The independent variable is \(t\), and the dependent variable is \(v\).

**Note:** A controlled variable is an independent variable.

At a restaurant, the waiting time is defined as the time between sitting down at a table and a waiter first arriving at your table. This waiting time is dependent upon the number of other customers already seated in the restaurant. John is a customer who visited the restaurant on 10 different days. The table shows, for each of these days, the number, \(x\), of customers already seated and his waiting time, in \(y\) minutes.

\begin{tabular}{|c|c c c c c c c c c c|} \hline \(x\) & 9 & 3 & 4 & 10 & 8 & 12 & 7 & 11 & 2 & 6 \\ \(y\) & 11 & 6 & 5 & 11 & 9 & 13 & 9 & 12 & 4 & 7 \\ \hline \end{tabular} _(Taken from GCE Jan 2006 ASE)_

Ans:The independent variable is \(x\), and the dependent variable is \(y\).

The following table shows the marks scored by 10 randomly selected students in a French test and in an English test.

\begin{tabular}{|c|c c c c c c c c c|} \hline French score, \(x\) & 20 & 43 & 33 & 56 & 50 & 67 & 73 & 68 & 77 & 43 \\ \hline English score, \(y\) & 19 & 42 & 44 & 52 & 51 & 53 & 66 & 56 & 60 & 37 \\ \hline \end{tabular}

Ans:From the above information, we are not able to determine which is dependent/independent variable.

### Scatter Diagram

A picture speaks a thousand words - what better way to obtain an overview of the relationship between variables than observing it from a diagram.

A **scatter diagram** is a two-dimensional plot, with the values of one variable plotted along each axis. By convention, we **plot the independent variable along the horizontal axis**.

[MISSING_PAGE_FAIL:4]

Note: When drawing a scatter diagram, ensure the relative position of the points are correct, and label the axes and range of the data:

#### Interpreting Scatter Diagrams

If all the points in a scatter diagram seem to lie close to a straight line, we say there is a **linear correlation** between the variables.

**Both the variables increase together. The points lie close to a straight line. We say that the variables have a strong positive linear correlation.**

**The points are further away from a straight line as compared to the first case. So the linear correlation here is not as strong as the first case.**

**There appears to be no clear relation between the variables.**

**There is a non-linear relation between the variables.**

Chapter S6: Correlation and Regression Page 5 of 26

## 2 Product Moment Correlation Coefficient

A scatter diagram shows visually the relation between two variables. In this section, we measure the strength of the linear relation between the variables by quantifying it.

The **product moment correlation coefficient**, denoted by \(r\), is a numerical measure of **the linear relation** between two variables.

### Calculating the Value of the Product Moment Correlation Coefficient

There are 2 equivalent formulae for the product moment correlation coefficient that can be found in the formula list, should one be required to compute it by hand when given a data set of \(n\) observations \((x,y)\).

\[r=\frac{\sum\bigl{(}x-\overline{x}\bigr{)}\bigl{(}y-\overline{y}\bigr{)}}{ \sqrt{\bigl{(}\sum\bigl{(}x-\overline{x}\bigr{)}^{2}\bigr{)}\bigl{\{}\sum\bigl{(} y-\overline{y}\bigr{)}^{2}\bigr{\}}}}\;\;\text{and}\;\;r=\frac{\sum xy-\frac{\sum x \sum y}{n}}{\sqrt{\biggl{(}\sum x^{2}-\frac{\bigl{(}\sum x\bigr{)}^{2}}{n} \biggr{)}\biggl{(}\sum y^{2}-\frac{\bigl{(}\sum y\bigr{)}^{2}}{n}\biggr{)}}}\]

How these two formulae came about is beyond the scope of the A-Level syllabus. But their equivalence is easy [Refer to Appendix].

Example 2: A data set of 10 observations \((x,y)\) are summarised below:

\[\sum x=72,\,\sum x^{2}=624,\,\,\,\sum y=87,\,\,\sum y^{2}=843,\,\,\sum xy=720\]

Calculate the value of the product moment correlation coefficient.

**Solution:**

The value of the product moment correlation coefficient is

\[r=\frac{720-\frac{(72)\sqrt{7}}{10}}{\sqrt{\biggl{(}(624)-\frac{(72)^{2}}{10} \biggr{)}\biggl{(}\bigl{(}843\bigr{)}-\frac{(87)^{2}}{10}\biggr{)}}}=0.982\,\,(3 \,\,\text{s.f.})\]

Remark:

In the A-Level examination, raw data is usually given. If you are required to use the formula, you can refer to the formula list.

### Properties of the Product Moment Correlation Coefficient

**(a)**: The value of \(r\) is independent of the units of the variables.
**(b)**: The correlation coefficient is a property of the bivariate data set itself and is not determined by which is the independent variable.
**(c)**: \(-1\!\leq\!r\!\leq\!1\)
**(d)**: Relationship between the value of \(r\) and the appearance of the scatter diagram

**Positive Linear Correlation, i.e. \(r\!>\!0\)**

**In a scatter plot, when an increase in one variable is generally associated with an increase in the second variable, we say that the two variables are positively correlated.**

The closer the value of \(r\) is to 1 the stronger the positive linear correlation between the two variables, i.e. the closer the points on the scatter diagram are to a straight line of positive gradient.

**Negative Linear Correlation, i.e. \(r\!<\!0\)**

**On the other hand, if an increase in one variable is associated with a decrease in the second variable, we then say that the two variables are negatively correlated.**

The closer the value of \(r\) is to \(-1\) the stronger the negative linear correlation, i.e. the closer the points on the scatter diagram are to a straight line of negative gradient.

**No Linear Correlation, i.e. \(r\approx 0\)**

**If the variables have a non-linear correlation, we will look at how to deal with such relationships in Section 5.**

Special values of \(r\)

**(i)**: \(r\!=\!1\): Perfect positive linear correlation between variables.

All data points lie exactly on a straight line of positive gradient.
**(ii)**: \(r\!=\!-1\): Perfect negative linear correlation between variables.

All data points lie exactly on a straight line of negative gradient.
**(iii)**: \(r\!=\!0\): **No linear correlation**. Note that this does not imply no relationship; the relation between variables may be modelled by another type of function.

### Interpreting Correlation

As much as the correlation coefficient can tell us about the relation between two variables, there are also pitfalls that one should avoid falling into when interpreting its value.

#### 2.3.1 Importance of Scatter Diagram

The correlation coefficient alone is insufficient for interpretation of relation between variables. The scatter diagram gives a picture of the correlation. It also helps to identify any results that are well away from the other points and so do not fit the general pattern of any correlation shown up by the diagram. Such a result is known as an **outlier**. Removing them gives a truer picture of the relation between the variables.

Example 3Two sets of bivariate data have correlation coefficients that are close to zero. The scatter diagrams for the two sets of data are shown below.

The scatter diagrams show that the variables in the first set of data have no clear relation, while those in the second set exhibit a non-linear relation.

**Example 4**:

Consider the following set of data:

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|} \hline \(x\) & 1 & 1 & 1 & 2 & 2 & 2 & 3 & 3 & 3 & 3 & 9 \\ \hline \(y\) & 1 & 2 & 3 & 1 & 2 & 3 & 1 & 2 & 3 & 8 \\ \hline \end{tabular}

It is given that the product moment correlation coefficient is 0.862 (3s.f.).

**(a)**: Assuming \(x\) is the independent variable, draw a scatter diagram for the set of data.
**(b)**: Is there a strong linear relation between the variables? Justify your answer.

**Answer:**

**(a)**: Although \(r=0.862\) is close to 1, which suggests a strong positive linear correlation between \(x\) and \(y\), the scatter diagram shows otherwise.

Note: The above inconsistency is most likely due to the presence of the outlier (9,8).

If we remove the outlier, then there is no linear relationship between the variables.

**Example 5**: **MJC Prelims 2007/02/Q9**

In an investigation of a shrub, research workers measured the average width \(y\) (in cm) and stem density \(x\) (number of stems per m\({}^{2}\)) at ten sites with the following results:

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|} \hline \(x\) & 4 & 5 & 6 & 9 & 11 & 14 & 15 & 19 & 21 & 22 \\ \hline \(y\) & 0.8 & 2 & 0.65 & 0.6 & 0 & 0.65 & 0.55 & 0.35 & 0.40 & 0.38 \\ \hline \end{tabular}
**(i)**: Calculate the correlation coefficient for the data.
**(ii)**: Give a sketch of the scatter diagram for the data, as shown on your calculator, and comment on your answer in **(i)**.
**(iii)**: Identify the two data pairs which should be removed.

#### 2.3.2 Correlation does not imply Causation

The existence of a linear correlation between two variables does not mean that the change in one variable causes the change in another.

For example, there may be a positive correlation between the average life expectancy of Singaporeans and the memory capacity of desktop computers, but this does not mean one is the cause of another. Both increases may be due to scientific development over time.

The product moment correlation coefficient merely gives an idea of the linear relationship between the variables. It does not imply any cause-and-effect relationship between the variables. There may be intermediate variables involved in the relationship which we do not know about, or there may even be more than one explanation to the linear relation.

[MISSING_PAGE_FAIL:11]

[MISSING_PAGE_EMPTY:12]

[MISSING_PAGE_FAIL:13]

[MISSING_PAGE_EMPTY:14]

**(i)** The equation of the least squares regression line of \(y\) on \(x\) is

\[y=2.32+0.886\,x\,,\]

with coefficients correct to 3 significant figures.

To find the least squares regression line of \(x\) on \(y\), we will enter the \(y\)-values in L\({}_{2}\) as values of the independent variable in the Xlist, while \(x\)-values in L\({}_{1}\) as values of the dependent variable in the Ylist.

[Note that it will not be useful to store the equation in this case as GC stores the variable entered in Xlist as \(x\) and the other entered in Ylist as \(y\).]

**(ii)** The equation of the least squares regression line of \(x\) on \(y\) is

\[x=1.09\,y-2.26\,,\]

with coefficients correct to 3 significant figures.

**(iii)** The product moment correlation coefficient is 0.982 (3 s.f.).

**(iv)** To find the values of \(\overline{x}\) and \(\overline{y}\), press [stat], then choose **CALC** and **2:2-Var Stats**.

Enter Xlist and Ylist.

Select **Calculate**.

From GC, \(\overline{x}=7.2\) and \(\overline{y}=8.7\).

**(iv)** To find the values of \(\overline{x}\) and \(\overline{y}\), press [stat], then choose **CALC** and **2:2-Var Stats**.

Enter Xlist and Ylist.

Select **Calculate**.

From GC, \(\overline{x}=7.2\) and \(\overline{y}=8.7\).

**(iv)** To find the values of \(\overline{x}\) and \(\overline{y}\), press [stat], then choose **CALC** and **2:2-Var Stats**.

Enter Xlist and Ylist.

Select **Calculate**.

From GC, \(\overline{x}=7.2\) and \(\overline{y}=8.7\).

**(iv)** To find the values of \(\overline{x}\) and \(\overline{y}\), press [stat], then choose **CALC** and **2:2-Var Stats**.

Enter Xlist and Ylist.

Select **Calculate**.

From GC, \(\overline{x}=7.2\) and \(\overline{y}=8.7\).

Enter Xlist and Ylist.

Select **Calculate**.

From GC, \(\overline{x}=7.2\) and \(\overline{y}=8.

Application and Interpretation

Regression lines can be used to make predictions.

Consider the following data set:

\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|} \hline \(x\) & **4** & 9 & 17 & 24 & 32 & 40 & 46 & 57 & 63 & 69 & 72 & **78** \\ \hline \(y\) & **6.85** & 6.75 & 6.74 & 6.73 & 6.68 & 6.52 & 6.54 & 6.48 & 6.36 & 6.33 & 6.35 & **6.29** \\ \hline \end{tabular}

Observe that the least and greatest values of \(x\) are 4 and 78 respectively, and that of \(y\) are 6.29 and 6.85 respectively.

Using the least squares regression line to predict or estimate missing values within the range of data (e.g. estimate \(y\) when \(x=5\) or estimate \(x\) when \(y=6.5\)) is known as **interpolation**. Using the line to estimate values outside the range of data is known as **extrapolation**.

Note that we do not know what happens outside the given range of experimental values. Extrapolating using values beyond the given data range is dangerous as the regression model (linear, quadratic, reciprocal, etc.) obtained may not be applicable outside the range of experimental data given.

The **least squares regression line of \(y\) on \(x\)** is used when

* \(x\) is the independent variable and \(y\) is the dependent variable; or
* the independent/dependent variable cannot be determined from the given information and you want to estimate \(y\) for a given value of \(x\).

The **least squares regression line of \(x\) on \(y\)** is used when

* \(y\) is the independent variable and \(x\) is the dependent variable; or
* the independent/dependent variable cannot be determined and you want to estimate \(x\) for a given value of \(y\).

When looking at the regression equation \(y=a+bx\), \(a\) is the \(y\)-intercept of the line, and \(b\) is the gradient of the line. \(a\) is the value of \(y\) when \(x=0\) and \(b\) is the amount by which \(y\) increases for every unit of increase in \(x\), so \(b\) is the rate of change of \(y\) with respect to \(x\). It is necessary to interpret the meaning of these values in the context provided.

**Example 7**:

A scientist working in agricultural research believes that there is a linear relationship between the amount of a certain food supplement given to hens and the hardness of the shells of the eggs they lay. As an experiment, controlled quantities of the supplement were added to the hens' normal diet and the hardness of the shells of the eggs was then measured on a scale from 1 to 10:

\begin{tabular}{|c|c|c|c|c|c|c|c|} \cline{2-10} \multicolumn{1}{c|}{Food supplement, \(x\) (g/day)} & 2 & 4 & 6 & 8 & 10 & 12 & 14 \\ \cline{2-10} \multicolumn{1}{c|}{Hardness of shells, \(y\)} & 3.2 & 5.2 & 5.5 & 6.4 & 7.2 & 8.5 & 9.8 \\ \hline \end{tabular}
**(i)**: Draw a scatter diagram for the data.
**(ii)**: Find the product moment correlation coefficient. Find also the equation of the regression line of \(y\) on \(x\). Give your answer in the form \(y=a+bx\), with \(a\) and \(b\) corrected to 3 decimal places.
**(iii)**: Estimate the shell hardness (correct to 1d.p.) for a food supplement of 11g per day, and comment on the reliability of your estimate.
**(iv)**: Explain what the values of \(a\) and \(b\) tell you and why you should not try to estimate the shell hardness for a food supplement of 20g per day.

**Solution:**

**(i)**:

\begin{tabular}{|c|c|c|c|c|c|} \hline
**Solution:** & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(i)} & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(ii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(ii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii)} & & & & & & & & \\ \cline{2-10} \multicolumn{1}{c|}{(iii

**Example 8**: The following data were collected during a study under experimental conditions, of the effect of temperature, \(x^{\circ}\)C, on the pH, \(y\), of skimmed milk.

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline \(x\) & 4 & 9 & 17 & 24 & 32 & 40 & 46 & 57 & 63 & 69 & 72 & 78 \\ \hline \(y\) & 6.85 & 6.75 & 6.74 & 6.73 & 6.68 & 6.52 & 6.54 & 6.48 & 6.36 & 6.33 & 6.35 & 6.29 \\ \hline \end{tabular}

Use the appropriate least squares regression line(s) to estimate

**(i)**: the pH of the skimmed milk when the temperature is 27 \({}^{\circ}\)C,
**(ii)**: the temperature (to the nearest \({}^{\circ}\)C) of the skimmed milk when the pH is measured to be 6.64.

**Solution:**:

Scatter Plot for own reference:

From GC, product moment correlation coefficient \(=-0.984\) (3sf)

Since this is a study of the effect of \(x\) on \(y\), so \(x\) is independent and \(y\) dependent. The least squares regression line of \(y\) on \(x\) with the following equation is used for both estimates:

\[y=6.8693-0.0074589\,x\] (5s.f.).

**(i)**: When \(x=27\), \(y=6.67\) (3 s.f.).

So the pH of the skimmed milk at 27 \({}^{\circ}\)C is estimated to be 6.67.

**(ii)**: When \(y=6.64\), we have \(x=31\) (nearest integer).

Thus the temperature of the skimmed milk is estimated to be 31 \({}^{\circ}\)C.

\begin{tabular}{|p{113.8pt}|p{113.8pt}|} \hline  & \multicolumn{1}{c

**Example 9**: The following table shows the marks scored by 10 randomly selected students in a French test and in an English test.

\begin{tabular}{|l|c c c c c c c c c c|} \hline French score, \(x\) & 20 & 43 & 33 & 56 & 50 & 67 & 73 & 68 & 77 & 43 \\ \hline English score, \(y\) & 19 & 42 & 44 & 52 & 51 & 53 & 66 & 56 & 60 & 37 \\ \hline \end{tabular}

Assume there is a linear correlation between the two scores.

**(i)**: A student, Tom, was absent for the French test. Predict a suitable mark for him if he scored 65 in his English test.
**(ii)**: Another student, Jerry, was absent for the English test. Predict a suitable mark for him if he scored 70 in his French test.
**Solution:**: Since neither variable is dependent on another, the choice of regression line depends on which value is being estimated.
**(i)**: Here we need to predict the \(x\)-value given a \(y\)-value, so we use the least squares regression line of \(x\) on \(y\):

\[x=1.2832\,y-8.5940\,\,(5\,\,\mathrm{s.f.})\]

When \(y=65\), \(x=75\) (nearest whole number).

Predicted mark for his French test is 75.
**(ii)**: Least squares regression line of \(y\) on \(x\):

\[y=0.65979x+13.031\,\,(5\,\,\mathrm{s.f.})\]

When \(x=70\), \(y=59\) (nearest whole number).

Predicted mark for his English test is 59.

## 5 Linearisation of Data

There are many cases where the relation between the variables will be non-linear. However, through a suitable transformation on the data, it may still be possible to find a linear relation between the variables for the transformed data.

Suppose variables \(x\) and \(y\) have a quadratic relationship \(y=ax^{2}+b\).

If we let \(X=x^{2}\), then the relationship becomes \(y=aX+b\).

This is a linear relation between \(y\) and \(X=x^{2}\).

### Example 10

In each of the following, variables \(x\) and \(y\) do not have a linear relationship. Identify the variables to be plotted on the axes in order to obtain a scatter diagram depicting a linear relationship.

\[\begin{array}{ll}&\textbf{Equation}\\ \textbf{(a)}&y=ax^{2}+b\\ \textbf{(b)}&y=\frac{a}{x}+b\\ \textbf{(c)}&y^{2}=a\sqrt{x}+b\\ \textbf{(d)}&y=ab^{x},\text{ where }a>0\text{ and }b>0\\ \end{array}\qquad\qquad\begin{array}{ll}&\textbf{Variables}\\ \textbf{y}&\text{ and }x^{2}\\ \textbf{y}&\text{ and }\frac{1}{x}\\ \textbf{y}^{2}&\text{ and }\sqrt{x}\\ \textbf{\ln }y&\text{ and }x\\ \textbf{\ln }y&\text{ and }x\\ \end{array}\]

For **(d)**, take the natural log of both sides of \(y=ab^{x}\) to get:

\[\begin{array}{ll}&\ln\,y=\ln\left(ab^{x}\right)\\ &\ln\,y=\ln a+\ln b^{x}\\ &\ln\,y=x\ln b+\ln a\\ \end{array}\]

### Example 11

The daily rate charged by a car-hire firm varies with the length of the hire period. The firm's brochure gave the following data.

\begin{tabular}{|l|c|c|c|c|c|c|c|c|} \hline Hire period, \(x\) days & 1 & 2 & 3 & 4 & 5 & 10 & 30 & 50 \\ \hline Daily rate, \$y & 149 & 119 & 115 & 112 & 109 & 105 & 103 & 101 \\ \hline \end{tabular}

**(i)**: Find the value of the product-moment correlation coefficient, and comment on this value.
**(ii)**: Explain which of the following cases is the most appropriate for modelling these values.

* \(y=a+bx\), where \(a\) is positive and \(b\) is negative,
* \(y=a+bx^{2}\), where \(a\) is positive and \(b\) is negative,
* \(y=a+\dfrac{b}{x}\), where \(a\) is positive and \(b\) is positive,
* \(y=a+b\ln x\), where \(a\) is positive and \(b\) is negative.

For the appropriate model, calculate the least squares regression line.

**Solution:**

**(i)**: The product moment correlation coefficient is \(-0.563\) (3 s.f.). There is a negative correlation between the hire period and the daily rate. Since the coefficient is not close to \(-1\), there is no strong linear correlation between the variables, as shown in the scatter plot.
**(ii)**: **Remark:**: **Always look at the scatter diagram before proceeding to find \(r\), in order to have an idea of the appropriateness of each model.**

We see from the scatter diagram that as the length of the hire period increases, the corresponding daily rate charged decreases at a decreasing rate. This trend is consistent with Model C or D.

We thus proceed to compare the product moment correlation coefficient for Model C and Model D.

\begin{tabular}{l l l}
**Model** & **Variables** & **Product moment correlation coefficient** \\ \hline C & \(\dfrac{1}{x}\) & and \(y\) & 0.992 (3sf) \\ D & \(\ln x\) & and \(y\) & -0.817 (3sf) \\ \hline \end{tabular}

Since the magnitude of 0.992 is closer to 1, then the most appropriate model is Model C.

The least squares regression line of \(\ y\) on \(\dfrac{1}{x}\) is

\[y=99.8+47.1\bigg{(}\dfrac{1}{x}\bigg{)}\]

with coefficients correct to 3 significant figures.

**Example 12 2008 RJC/II/13 (modified)**

A stationery retailer supplies pens to offices. In order to encourage customers to buy in bulk, the stationery retailer came up with the following price scheme.

\begin{tabular}{|l|c|c|c|c|c|c|} \hline Number of pens ordered, \(x\) & 5 & 10 & 20 & 40 & 80 & 160 \\ \hline Unit price in dollar, \(y\) & 1.50 & 1.20 & 1.10 & 0.99 & 0.90 & 0.80 \\ \hline \end{tabular}

[1]

**(i)**: Calculate the value of the product moment correlation coefficient.
**(ii)**: Give a sketch of the scatter diagram for the data and hence comment on the value of the product moment correlation coefficient found in **(i)**.
**(iii)**: State, with a reason, which model of the form \(\ y=a+bw\) is appropriate, where \(a\) and \(b\) are constants, \(\ b>0\) and \(w\) is as follows.

**(iv)**: the value of the product moment correlation coefficient,
**(v)**: the equation of the regression line of \(y\) on \(w\), and hence obtain an estimate of the number of pens ordered when a unit price of $1.40 is quoted.

Comment on the reliability of your answer.

**Solution**

**(i)**: Value of the product moment correlation coefficient is \(-0.807\) (3 s.f.).
**(ii)**: \(y\)

The value found in **(i)** suggests there is some form of negative linear correlation between \(\ x\) and \(\ y\) but the scatter diagram shows that the relationship between \(\ x\) and \(\ y\) is non-linear. Thus, the value of the product moment correlation coefficient is not a good indication of the linearity between \(\ x\) and \(\ y\).

**(ii)**: The value found in **(i)** suggests there is some form of negative linear correlation between \(\ x\) and \(\ y\) but the scatter diagram shows that the relationship between \(\ x\) and \(\ y\) is non-linear. Thus, the value of the product moment correlation coefficient is not a good indication of the linearity between \(\ x\) and \(\ y\).

**(iii)** From the scatter diagram, we see that \(y\) decreases as \(x\) increases, which is the case for model **B** ( \(y=a+\frac{b}{x},\ b>0\)). For models **A** ( \(y=a+bx^{2}\)) and **C** ( \(y=a+b\ln x\)), \(y\) increases as \(x\) increases, since \(b>0\). Hence model **B** is appropriate.

**(iv)** Value of the product moment correlation coefficient between \(y\) and \(w\) is 0.976 (3 s.f.).

**(v)** Equation of the regression line of \(y\) on \(w\) is \(y=0.86652+3.2785_{W}\) (5 s.f.),

i.e. \(y=0.867+3.28_{W}\) (3 s.f.).

When \(y=1.4\), \(1.4=0.86652+3.2785_{W}\)

\(\Rightarrow w=0.16272\)\(\Rightarrow x=6.15=6\) (to nearest whole number)

An estimate of the number of pens ordered when a unit price of $1.40 is quoted is 6.

This estimate is highly reliable since \(y=1.4\) is between the range of values of \(y\) from 0.80 to 1.50, and the product moment correlation coefficient between \(y\) and \(w\) is 0.976 (3 s.f.), which suggests a strong positive linear correlation between \(y\) and \(w\).

**Remarks:**

A near-zero value for the product moment correlation coefficient only implies the absence of a linear relation between the variables. The scatter diagram must be considered when drawing conclusions about the relation, or absence of relations between variables. A non-linear relation may still exist. Even if the product moment correlation coefficient suggests a fairly strong linear relation between the variables, a non-linear model may still provide a better fit and consequently better predictive power.

**CONCLUSION**

The ideas presented in this chapter are but an introduction to the study of correlation and regression analysis on a set of bivariate data. In practice, statistical analysis is often done with the aid of computer programs. Microsoft Excel provides a simple and convenient avenue for data entry and analysis, while those seeking more rigorous analytical tools may want to consider more specialized software such as SPSS or Minitab. The study of correlation between variables and the addition of predictive power via regression analysis underpins much of scientific discovery and formation of business strategies - the same fundamental concepts are employed in the early detection of fetal abnormalities, in the study of the nature of galaxies as well as in the prediction of stock-market trends. Those wishing to take a little time off to explore further considerations in this study will find a wealth of resources online by a simple search of the chapter's title.

Many examples drawn from the study of biostatistics are available here -

[http://www.uth.tmc.edu/uth_orgs/educ_dev/oser/L3_1.HTM](http://www.uth.tmc.edu/uth_orgs/educ_dev/oser/L3_1.HTM)

Chapter S6: Correlation and Regression

[MISSING_PAGE_EMPTY:25]

Summary